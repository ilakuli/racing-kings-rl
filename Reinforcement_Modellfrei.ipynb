{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e7b297",
   "metadata": {},
   "source": [
    "# Reinforcement Learning mit Python - Running Kings Schach KI\n",
    "## Aufgabenstellung\n",
    "\n",
    "Erstellen  Sie  Modelle,  welche  das  Spiel  Racing  Kings erlernen.  Am  Ende  sollte  ein  Spiel  gegen  den erstellten  Algorithmus  möglich  sein.  Testen  Sie  als  Gegner  einenAlgorithmus,  welcher  Zufallszüge ausführt,  und  bewerten  Sie  ihren  Algorithmus. Nutzen  Sie  die  chess-Bibliothek  (https://python-chess.readthedocs.io/en/latest/)\n",
    "\n",
    "Bonus: Vergleichen Sie einen modellfreien und einen modellbasierten Ansatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f6d9c",
   "metadata": {},
   "source": [
    "Diese Anleitung wurde verwendet um zügig mit der verwendung der chess bibliothek starten zu können.\n",
    "https://jupyter.brynmawr.edu/services/public/dblank/CS371%20Cognitive%20Science/2016-Fall/Programming%20a%20Chess%20Player.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5597cd2",
   "metadata": {},
   "source": [
    "# Install Libraries (MacOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b544f",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "!pip3 install numpy\n",
    "!pip3 install chess\n",
    "!pip3 install pydot\n",
    "!pip3 install gym\n",
    "!pip3 install stable_baselines3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db48cc",
   "metadata": {},
   "source": [
    "# Define chess environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f138933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_board(board, use_svg):\n",
    "    if use_svg:\n",
    "        return board._repr_svg_()\n",
    "    else:\n",
    "        return \"<pre>\" + str(board) + \"</pre>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a40e58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def who(player):\n",
    "    return \"White\" if player == chess.WHITE else \"Black\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be19484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess.variant\n",
    "import random\n",
    "import time\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym.spaces import Discrete, Box, Dict\n",
    "\n",
    "N_DISCRETE_ACTIONS = 4096\n",
    "\n",
    "# from Learning_Chess pdf\n",
    "class RacingKingsEnvironment(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(RacingKingsEnvironment, self).__init__()\n",
    "        self.board = chess.variant.RacingKingsBoard()\n",
    "        self.reward = 0\n",
    "        self.action_space = Discrete(N_DISCRETE_ACTIONS)\n",
    "        self.observation_space = Box(low=0, high=1, shape=(14, 8, 8), dtype=np.uint8)\n",
    "    def board_square_to_index(self, name):\n",
    "        return (int(name[1])-1) * 8 + (ord(name[0])-97) \n",
    "    def action_index_to_uci(self, index):\n",
    "        index_from = index//64\n",
    "        index_to = index%64\n",
    "        name = chr(index_from%8 + 97) + str(index_from//8 +1) + chr(index_to%8 + 97) + str(index_to//8 + 1)\n",
    "        return name\n",
    "    def action_uci_to_index(self, uci):\n",
    "        index_from = (int(uci[1])-1) * 8 + (ord(uci[0])-97) \n",
    "        index_to = (int(uci[3])-1) * 8 + (ord(uci[2])-97) \n",
    "        return index_from*64 + index_to\n",
    "    @property\n",
    "    def actions(self):\n",
    "        moves = list(self.board.legal_moves)\n",
    "        moves_string = []\n",
    "        for move in moves:\n",
    "            moves_string.append(move.uci())\n",
    "        boardActions = np.zeros(N_DISCRETE_ACTIONS, dtype=np.int8)\n",
    "        for move in moves_string:\n",
    "            boardActions[self.board_square_to_index(move[0:2])*64 + self.board_square_to_index(move[2:4])] = 1\n",
    "        return boardActions\n",
    "    @property\n",
    "    def states(self):\n",
    "        boardState = np.zeros((14, 8, 8), dtype=np.int8)\n",
    "        for piece in chess.PIECE_TYPES:\n",
    "            for square in self.board.pieces(piece, chess.WHITE):\n",
    "                idNum = square//8\n",
    "                idAlph = square%8\n",
    "                boardState[piece - 1][7 - idNum][idAlph] = 1\n",
    "            for square in self.board.pieces(piece, chess.BLACK):\n",
    "                idNum = square//8\n",
    "                idAlph = square%8\n",
    "                boardState[piece + 5][7 - idNum][idAlph] = 1        \n",
    "        \n",
    "            aux = self.board.turn\n",
    "            self.board.turn = chess.WHITE\n",
    "            for move in list(self.board.legal_moves):\n",
    "                square = self.board_square_to_index(move.uci())\n",
    "                idNum = square//8\n",
    "                idAlph = square%8\n",
    "                boardState[12][7 - idNum][idAlph] = 1\n",
    "            self.board.turn = chess.BLACK\n",
    "            for move in list(self.board.legal_moves):\n",
    "                square = self.board_square_to_index(move.uci())\n",
    "                idNum = square//8\n",
    "                idAlph = square%8\n",
    "                boardState[13][7 - idNum][idAlph] = 1\n",
    "            self.board.turn = aux\n",
    "        return boardState\n",
    "    \n",
    "    def step(self, action, isGame = False):\n",
    "        done = False\n",
    "        step_reward = 0\n",
    "        info = {}\n",
    "        \n",
    "        # check if it is not your turn -> then make a random move\n",
    "        # when uncommenting this code the ai will play moves for both players\n",
    "        if not isGame:\n",
    "            if self.board.turn == chess.WHITE:\n",
    "                try:\n",
    "                    self.board.push(random.choice(list(self.board.legal_moves)))\n",
    "                    info = {\"msg\":\"White Did a valid move\"}\n",
    "                except:\n",
    "                    info = {\"msg\":\"Passed an already finished board\"} \n",
    "                    done = True\n",
    "          \n",
    "\n",
    "        if not self.board.is_game_over(claim_draw=True):\n",
    "            if action is not None:\n",
    "                try:\n",
    "                    self.board.push_uci(self.action_index_to_uci(action))\n",
    "                    #step_reward += 1\n",
    "                    info = {\"msg\":\"Did a valid move\"}\n",
    "                except:\n",
    "                    #step_reward -= 1\n",
    "                    info = {\"msg\":\"Action is not a valid move\"}\n",
    "                    done = True\n",
    "                \n",
    "                if self.board.is_variant_end():\n",
    "                    if who(not self.board.turn) == \"Black\":\n",
    "                        step_reward += 100\n",
    "                        info = {\"msg\":\"AI won the game!\"} \n",
    "                        done = True\n",
    "                    else:\n",
    "                        step_reward -= 100\n",
    "                        info = {\"msg\":\"Opponent won the game!\"} \n",
    "                        done = True\n",
    "                    #info = {\"msg\":\"racing kings: \" + who(not self.board.turn) + \" wins!\"}\n",
    "        else:\n",
    "            step_reward -=10\n",
    "            done = True\n",
    "            info = {\"msg\":\"game over\"}\n",
    "\n",
    "        self.reward += step_reward\n",
    "        \n",
    "        \n",
    "        return self.states, step_reward, done, info\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        # reset the board\n",
    "        self.board.reset()\n",
    "        # play random amount of actions\n",
    "        for i in range((random.randint(0, 30)*2)):\n",
    "            try:\n",
    "                move = random.choice(list(self.board.legal_moves))\n",
    "                self.board.push(move)\n",
    "            except:\n",
    "                self.board.reset()\n",
    "                \n",
    "        self.reward = 0.0\n",
    "        return self.step(None)[0]  # reward, done, info can't be included\n",
    "    \n",
    "    \n",
    "    def render(self, mode=\"human\", pause=0.2):\n",
    "        name = who(self.board.turn)\n",
    "        use_svg = (mode == \"human\")\n",
    "        board_stop = display_board(self.board, use_svg)\n",
    "        html = \"<b>Move %s %s:</b><br/>%s\" % (\n",
    "                    len(self.board.move_stack), name, board_stop)\n",
    "        if mode is not None:\n",
    "                if mode == \"human\":\n",
    "                    clear_output(wait=True)\n",
    "                display(HTML(html))\n",
    "                if mode == \"human\":\n",
    "                    time.sleep(pause)\n",
    "    def close (self):\n",
    "        print(\"closing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5468d93",
   "metadata": {},
   "source": [
    "# Test Functionality of Chess environment randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc8278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set number of test games\n",
    "episodes = 10\n",
    "# Create Environment using RacingKings class defined above\n",
    "env = RacingKingsEnvironment()\n",
    "# Start test loop\n",
    "for episode in range(1, episodes+1):\n",
    "    # Reset environment\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    # Start game loop\n",
    "    while not done:\n",
    "        # Disable Rendering for speed enhancement\n",
    "        env.render(mode=None)\n",
    "        # Create sample move from action space\n",
    "        action = env.action_space.sample()\n",
    "        # Make step\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    # Print out game info\n",
    "    print('Episode:{} Score:{} Info:{}'.format(episode, score, info))\n",
    "# Closing environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd1a47a",
   "metadata": {},
   "source": [
    "# Training and saving Model using stable baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eaa6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy \n",
    "from stable_baselines3.common.callbacks import EvalCallback \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e127d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save path for Log Files\n",
    "logging_path = os.path.join('Training', 'Logs') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9467ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Environment using RacingKings class defined above\n",
    "env = RacingKingsEnvironment()\n",
    "# Vectorize environment\n",
    "env = DummyVecEnv([lambda: env]) \n",
    "# Create model using PPO algorithm and MLP Policy, verbose=1 for Info return\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=logging_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save path for callback model saving\n",
    "best_save_path = os.path.join('Training', 'SavedModels', 'Best_Racing_Kings')\n",
    "# Define callback for training saving best model every 20k timesteps\n",
    "eval_callback = EvalCallback(env, eval_freq=20000, best_model_save_path = best_save_path, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start model training using callback defined above\n",
    "model.learn(total_timesteps=100000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c152a8d6",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save path for trained model\n",
    "Model_Path = os.path.join('Training', 'SavedModels', 'PPO_Racing_Kings_Alex_neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using defined save path\n",
    "model.save(Model_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bbeda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model from\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from defined path (Use also to load already trained model)\n",
    "model = PPO.load(Model_Path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd74d354",
   "metadata": {},
   "source": [
    "# Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6eea45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate trained model using evaluate policy from Stable Baselines \n",
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d4f3a",
   "metadata": {},
   "source": [
    "# Play Game Human vs AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee975abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment from class RacingKings\n",
    "env = RacingKingsEnvironment()\n",
    "# Define necessary variables\n",
    "obs = None\n",
    "done = False\n",
    "score = 0\n",
    "# Reset chess board to ensure fresh start\n",
    "env.board.reset()    \n",
    "# Start game loop\n",
    "while not done:\n",
    "    #Activate render mode \n",
    "    env.render()\n",
    "    # Check if turn is white or black (Human plays white)\n",
    "    if who(env.board.turn) == 'White':\n",
    "        # Print out formatted list of possible moves at each step as a reminder for human player\n",
    "        print('Gueltige Züge:')\n",
    "        legal_moves = list(env.board.legal_moves)\n",
    "        legal_moves = map(lambda move: move.uci(), legal_moves)\n",
    "        print(*legal_moves, sep = \", \")\n",
    "        # Ask for human step via input of UCI move     \n",
    "        action = env.action_uci_to_index(input ('Ihr nächster Zug:'))\n",
    "        # Make step (Parameter 'True' to trigger game functionality in environment)\n",
    "        obs, reward, done, info = env.step(action,True)\n",
    "        score+=reward\n",
    "        \n",
    "    else:\n",
    "        # Create AI step using predict function\n",
    "        action = model.predict(obs)\n",
    "        # Make step (position 0 because predict function returns tuple)\n",
    "        obs, reward, done, info = env.step(action[0],True)\n",
    "        score+=reward\n",
    "# End game loop\n",
    "\n",
    "# Render last state of chess board after game ends        \n",
    "env.render()\n",
    "# Print out game info\n",
    "print('Score:{} Info:{}'.format(score, info))\n",
    "# Closinq environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256928c",
   "metadata": {},
   "source": [
    "# Play Game Random vs AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfcbe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment from class RacingKings\n",
    "env = RacingKingsEnvironment()\n",
    "# Define necessary variables\n",
    "obs = None\n",
    "done = False\n",
    "score = 0 \n",
    "# Reset chess board to ensure fresh start\n",
    "env.board.reset() \n",
    "# Start game loop\n",
    "while not done:\n",
    "    #Activate render mode (can be commented out for enhanced speed)\n",
    "    env.render()\n",
    "    # Check if turn is white or black (Random plays white)   \n",
    "    if who(env.board.turn) == 'White':\n",
    "        # Create random move from list of legal moves\n",
    "        legal_moves = list(env.board.legal_moves)\n",
    "        random_move = random.choice(legal_moves)\n",
    "        # Convert random move from UCI to Index\n",
    "        action = env.action_uci_to_index(random_move.uci())\n",
    "        # Make step (Parameter 'True' to trigger game functionality in environment)\n",
    "        obs, reward, done, info = env.step(action,True)\n",
    "        score+=reward\n",
    "        \n",
    "    else:\n",
    "        # Create AI step using predict function\n",
    "        action = model.predict(obs)\n",
    "        # Make step (position 0 because predict function returns tuple)\n",
    "        obs, reward, done, info = env.step(action[0],True)\n",
    "        score+=reward\n",
    "# End game loop\n",
    "\n",
    "# Render last state of chess board after game ends \n",
    "env.render()\n",
    "# Print out game info\n",
    "print('Score:{} Info:{}'.format(score, info))\n",
    "# Closinq environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902a061",
   "metadata": {},
   "source": [
    "# Play Game Random vs Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af29032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to test environment and enhance game comprehension\n",
    "\n",
    "# Create environment from class RacingKings\n",
    "env = RacingKingsEnvironment()\n",
    "# Define necessary variables\n",
    "obs = None\n",
    "done = False\n",
    "score = 0\n",
    "# Reset chess board to ensure fresh start\n",
    "env.board.reset()\n",
    "# Start game loop\n",
    "while not done:\n",
    "    #Activate render mode (can be commented out for enhanced speed)\n",
    "    env.render()\n",
    "    # Create random move from list of legal moves\n",
    "    legal_moves = list(env.board.legal_moves)\n",
    "    random_move = random.choice(legal_moves)\n",
    "    # Convert random move from UCI to Index\n",
    "    action = env.action_uci_to_index(random_move.uci())\n",
    "    # Make step (Parameter 'True' to trigger game functionality in environment)\n",
    "    obs, reward, done, info = env.step(action,True)\n",
    "    score+=reward\n",
    "# End game loop\n",
    "\n",
    "# Render last state of chess board after game ends \n",
    "env.render()\n",
    "# Print out game info\n",
    "print('Score:{} Info:{}'.format(score, info))\n",
    "# Closinq environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ad3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
